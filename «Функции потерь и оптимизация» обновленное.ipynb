{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961e9ef2-848d-4d91-b2d6-9ee7b0921592",
   "metadata": {},
   "source": [
    "# Домашнее задание к занятию «Функции потерь и оптимизация» обновленное"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f5518-b98d-4f0d-be08-28a9dbc6e57e",
   "metadata": {},
   "source": [
    "Цель: изучить применение методов оптимизации для решения задачи классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318464b-cb1d-4f09-9dd8-3eaba24110d7",
   "metadata": {},
   "source": [
    "Описание задания:\n",
    "В домашнем задании необходимо применить полученные знания в теории оптимизации и машинном обучении для реализации логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d62f3-7f7b-4c21-8d28-ada40117218d",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f0d31e-9d5c-484d-b08b-1ceef9090181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d94b7b6-a8a0-43cd-94ff-97697c3c0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a6118b-7cb7-45fb-87b2-501efe76abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline  # используем пайплайны для удобства\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a3169ea-80de-4ca3-83af-a1355053bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de4f0a14-1eca-478a-bd27-a8377131c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0add27c-0e6d-43ac-b7ba-2e246b865265",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab97b3e0-82dd-4555-a232-6d1a59922eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "mask = np .isin(iris.target, [1, 2])  # выбрать только Versicolor и Virginica\n",
    "X = iris.data[mask]\n",
    "y = iris.target[mask] - 1             # перекодирование классов: 0 и 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc58ded-640d-45aa-8469-d6e24c6ebd2a",
   "metadata": {},
   "source": [
    "## 2. Функция сигмоид"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd20f03-ddc0-4eff-89dc-1ba9d25e2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc04b12-fb95-4089-b273-33dc236fb69d",
   "metadata": {},
   "source": [
    "## 3. Реализация логистической регрессии с методом градиентного спуска"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78507c-eb7f-4591-a34c-513c31ecb3dd",
   "metadata": {},
   "source": [
    "Градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c89d4f48-24e7-4594-9de1-9c8cc0d6fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_gradient_descent(X, y, learning_rate=0.01, num_iterations=1000):\n",
    "    n_samples, n_features = X.shape\n",
    "    weights = np.zeros(n_features)                                  # инициализация весов\n",
    "    bias = 0                                                       # инициализация смещения\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        linear_model = np.dot(X, weights) + bias\n",
    "        y_predicted = sigmoid(linear_model)                        # предсказанная вероятность\n",
    "        dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))      # градиент весов\n",
    "        db = (1 / n_samples) * np.sum(y_predicted - y)             # градиент смещения\n",
    "\n",
    "                                                                # обновление параметров\n",
    "        weights -= learning_rate * dw\n",
    "        bias -= learning_rate * db\n",
    "    \n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bbbe89-0800-4e81-aa87-3b8a915bc41f",
   "metadata": {},
   "source": [
    "## 4. Реализация логистической регрессии с методом RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d0a3bd-06ac-44e3-b78e-f12e2a8138eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rmsprop(X, y, learning_rate=0.01, num_iterations=1000, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    n_samples, n_features = X.shape\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0\n",
    "    m = np.zeros(n_features)                                     # накопленный средний градиент\n",
    "    v = np.zeros(n_features)                                     # накопленная средняя квадрата градиента\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        linear_model = np.dot(X, weights) + bias\n",
    "        y_predicted = sigmoid(linear_model)\n",
    "        dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "        db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "\n",
    "        m = beta1 * m + (1 - beta1) * dw\n",
    "        v = beta2 * v + (1 - beta2) * (dw ** 2)\n",
    "        weights -= learning_rate * m / (np.sqrt(v) + epsilon)\n",
    "        bias -= learning_rate * db\n",
    "\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e83ce4c-2e30-4900-b791-7886e78c71b6",
   "metadata": {},
   "source": [
    "## 5. Реализация логистической регрессии с методом Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13721431-9991-4e18-87c1-3ed8cf36a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_nadam(X, y, learning_rate=0.01, num_iterations=1000, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    n_samples, n_features = X.shape\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0\n",
    "    m = np.zeros(n_features)\n",
    "    v = np.zeros(n_features)\n",
    "    t = 0\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        t += 1\n",
    "        linear_model = np.dot(X, weights) + bias\n",
    "        y_predicted = sigmoid(linear_model)\n",
    "        dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "        db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "\n",
    "        m = beta1 * m + (1 - beta1) * dw\n",
    "        v = beta2 * v + (1 - beta2) * (dw ** 2)\n",
    "\n",
    "        m_hat = m / (1 - beta1 ** t)                                            # корректировка первого момента\n",
    "        v_hat = v / (1 - beta2 ** t)                                            # корректировка второго момента\n",
    "\n",
    "        weights -= learning_rate * (m_hat / (np.sqrt(v_hat) + epsilon) + beta1 * m_hat)\n",
    "        bias -= learning_rate * db\n",
    "\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05495bb-9bbc-454e-9bb3-8036385d7f3d",
   "metadata": {},
   "source": [
    "## 6. Дополнительные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d32c8a57-f595-44d0-8b91-54f7ed071b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights, bias):\n",
    "    linear_model = np.dot(X, weights) + bias\n",
    "    y_predicted_prob = sigmoid(linear_model)\n",
    "    return (y_predicted_prob >= 0.5).astype(int)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93f5bb7-5e4a-434f-adef-bb8602000d7c",
   "metadata": {},
   "source": [
    "## 7. Проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574ed154-1417-4010-9f3f-1d51d9794644",
   "metadata": {},
   "source": [
    "Подготовка расчетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5075557c-6025-41bd-b0c1-4004d954d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"Gradient Descent\": fit_gradient_descent,\n",
    "    \"RMSProp\": fit_rmsprop,\n",
    "    \"Nadam\": fit_nadam,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acede4be-4764-4d01-8934-f7ffbecad3ed",
   "metadata": {},
   "source": [
    "Обучение моделей и сбор результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d07502be-a87d-4de3-9281-4bd0201e6554",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for method_name, method_func in methods.items():\n",
    "    start_time = time.time()\n",
    "    weights, bias = method_func(X, y)\n",
    "    end_time = time.time()\n",
    "    y_pred = predict(X, weights, bias)\n",
    "    acc = accuracy(y, y_pred)\n",
    "    elapsed_time = end_time - start_time\n",
    "    results.append((method_name, acc, elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dee5523-18f1-410f-9747-b9c02fafa3d0",
   "metadata": {},
   "source": [
    "Вывод результатов в виде таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5731da5-f53c-4697-8114-070997ea9fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Метод                | Точность (Accuracy) | Время работы (сек) |\n",
      "|----------------------|---------------------|--------------------|\n",
      "| Gradient Descent     | 0.9600              | 0.0084           |\n",
      "| RMSProp              | 0.9300              | 0.0118           |\n",
      "| Nadam                | 0.9600              | 0.0138           |\n"
     ]
    }
   ],
   "source": [
    "print(\"| Метод                | Точность (Accuracy) | Время работы (сек) |\")\n",
    "print(\"|----------------------|---------------------|--------------------|\")\n",
    "for method_name, acc, elapsed_time in results:\n",
    "    print(f\"| {method_name:20} | {acc:.4f}              | {elapsed_time:.4f}           |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a039e8-8d7a-4819-a5e3-261ca1374c84",
   "metadata": {},
   "source": [
    "## 8. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3378c186-2565-42b4-8f58-15b5d4587677",
   "metadata": {},
   "source": [
    "В процессе работы написаны функции для различных методовов реализации логистической регрессии. Ответы выведены в отдельную таблицу. Лучший результат показали Градиентный спуск и Nadam. А учитывая почти в 2 раза меньшие временные затраты, лучшим методом себя обычный градиентный спуск."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
